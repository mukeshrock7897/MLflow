{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a801bd",
   "metadata": {},
   "source": [
    "\n",
    "# 01\\_Datasets\\_Embeddings\\_HF\\_Cache\\_and\\_Stores\n",
    "\n",
    "## 🤔 Why it matters\n",
    "\n",
    "* 📚 **Datasets** define truth.\n",
    "* 🧠 **Embeddings** drive recall.\n",
    "* 💾 **HF cache** keeps downloads fast & reproducible.\n",
    "* 🗄️ **Vector stores** make retrieval low-latency at scale.\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Datasets (treat like code)\n",
    "\n",
    "* 🧱 **Schema**: `id`, `text`, `title?`, `meta{}` , `label?`\n",
    "* ✂️ **Splits**: `train / val / test` (no leakage!)\n",
    "* 🧼 **Quality**: dedup, normalize whitespace, strip boilerplate\n",
    "* 🧯 **PII**: redact/anonymize before embedding\n",
    "* 🏷️ **Dataset card**: source, license, cleaning steps\n",
    "* 🧊 **Snapshot**: parquet/JSONL + **hash** (log to MLflow)\n",
    "* 🎯 **Eval set**: balanced, **adversarial** items included\n",
    "\n",
    "**Log (MLflow)** → `dataset.id`, `dataset.hash`, `split`, `n_samples` ✅\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Embeddings (choices that matter)\n",
    "\n",
    "* 🧩 **Model**: multilingual? domain-tuned? dimension? context len?\n",
    "* ⚖️ **Trade-off**: recall vs latency vs cost\n",
    "* 🔣 **Instruction/pooling**: record **instruction text** & pooling method\n",
    "* 📏 **Preproc**: lowercasing, unicode normalize, stopwords? (be consistent)\n",
    "* 🧷 **What to embed**: chunk text **+ title + breadcrumbs** (better recall)\n",
    "* 🔁 **Query vs doc**: sometimes **different** encoders/instructions\n",
    "\n",
    "**Key metrics** → `hit@k`, `recall`, `MRR/NDCG`, `context_precision`, `diversity@k`\n",
    "**Log (MLflow)** → `embed.model`, `dim`, `instruction`, `pooling`, `norm=True/False`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧵 Chunking (quick guardrails)\n",
    "\n",
    "* 📐 **Size/overlap**: 500–1000 chars, **10–20% overlap** (start simple)\n",
    "* 🧭 **Semantic splits** (headings/sentences) > blind fixed splits\n",
    "* 🏷️ **IDs**: `doc_id`, `chunk_id`, offsets; store in metadata\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ HF Cache (Hugging Face)\n",
    "\n",
    "* 🗂️ **Locations**:\n",
    "\n",
    "  * Models → `~/.cache/huggingface/hub`\n",
    "  * Datasets → `~/.cache/huggingface/datasets`\n",
    "* 🛠️ **Control**: set `HF_HOME`, `HF_DATASETS_CACHE`, `TRANSFORMERS_CACHE`\n",
    "* 📌 **Pin revisions**: use **commit SHA** for models/datasets\n",
    "* ✈️ **Offline mode**: warm cache in CI; avoid cold starts\n",
    "* 🧹 **Hygiene**: prune old revs; avoid cache explosions\n",
    "\n",
    "**Log (MLflow)** → `hf.model_ref@sha`, `hf.dataset_ref@sha`\n",
    "\n",
    "---\n",
    "\n",
    "## 🗄️ Vector Stores (pick by scale & ops)\n",
    "\n",
    "| Store                    | Best for           | Notes                                  |\n",
    "| ------------------------ | ------------------ | -------------------------------------- |\n",
    "| 🧱 **FAISS**             | Local/small-medium | File-based, super fast, no filters     |\n",
    "| 🐘 **pgvector**          | SQL + vectors      | Easy ops, good filters, moderate scale |\n",
    "| 🚀 **Milvus/Zilliz**     | High scale         | HNSW/IVF-PQ, filters, mature           |\n",
    "| 🍍 **Pinecone/Weaviate** | Managed            | Fast start, pay-per-usage              |\n",
    "| 🔎 **OpenSearch/ES**     | Hybrid BM25+vec    | Great metadata filtering               |\n",
    "\n",
    "**Index knobs**\n",
    "\n",
    "* 🧭 **HNSW**: `M`, `efConstruction`, `efSearch`\n",
    "* 🧮 **IVF-PQ**: `nlist`, `nprobe`, codebooks\n",
    "* 🎛️ **Filters**: tags/date/tenant; plan **hybrid** (BM25 + vec) + **reranker**\n",
    "\n",
    "**Ops metrics** → QPS, p95 latency, recall\\@k on canary set, index size, RAM, build time\n",
    "\n",
    "**Log (MLflow)** → `index.type`, `index.params`, `store.uri`, `index.fingerprint`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Caching for \\$\\$ & speed\n",
    "\n",
    "* 🔁 **Query embedding cache** (LRU/Redis)\n",
    "* ♻️ **Provider cache** (if available) for repeated prompts\n",
    "* 📦 **Chunk dedup**: hash chunks; skip re-embedding unchanged text\n",
    "\n",
    "---\n",
    "\n",
    "## 🔐 Governance & deletion\n",
    "\n",
    "* 📝 **Lineage**: dataset → embed model → index version\n",
    "* 🧨 **Right to forget**: tombstones + reindex plan\n",
    "* 🔒 **Access**: per-tenant namespaces; encrypt at rest/in-flight\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Minimal “what to log” (per build)\n",
    "\n",
    "* 🏷️ `dataset.id/hash`, `split`, `n`\n",
    "* 🧠 `embed.model`, `dim`, `instruction`, `pooling`, `normalize`\n",
    "* ✂️ `chunk.size/overlap`, `splitter`\n",
    "* 🗄️ `store.type/uri`, `index.type/params`, `index.fingerprint`\n",
    "* 📊 `hit@k`, `recall`, `latency_ms_p95`, `size_gb`, `build_min`\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Common pitfalls\n",
    "\n",
    "* 🌀 Mixing embed models/dims across runs → broken cosine sims\n",
    "* 🧪 Changing eval set mid-comparison\n",
    "* 🧷 Forgetting **instruction text** (hidden drift!)\n",
    "* 🗂️ No delete strategy → compliance risk\n",
    "* 🧼 Embedding raw PII/secrets\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Quick wins\n",
    "\n",
    "* 🧊 Freeze **parquet snapshot + hash**; log to MLflow\n",
    "* 🧱 Embed **title + path** with text for better recall\n",
    "* 🧮 Track **context\\_use\\_rate** (retrieved docs actually used?)\n",
    "* 🔁 Cache query embeddings; cap `k`; rerank before LLM to cut tokens\n",
    "* 📌 Pin HF **commit SHAs**; pre-warm caches in CI\n",
    "\n",
    "---\n",
    "\n",
    "## 🗣️ One-liner\n",
    "\n",
    "**“Version your data, pin your embeddings, warm your HF caches, and fingerprint your index—so retrieval stays fast, cheap, and reproducible.”**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
