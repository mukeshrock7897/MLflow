{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”¹ 5. ðŸ§° **Custom Agents & Logging Extensions**\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ **What It Does**\n",
    "\n",
    "This section focuses on **tracking, extending, and enhancing GenAI/Agentic pipelines** â€” especially LangChain or LangGraph-based workflows â€” using custom PythonModel wrappers, prompt tracking, step-level logs, and external logging frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ **Common Use in GenAI/Agentic AI**\n",
    "\n",
    "| Scenario                      | MLflowâ€™s Role                                                 |\n",
    "| ----------------------------- | ------------------------------------------------------------- |\n",
    "| LangChain or LangGraph Agents | Wrap full pipelines using `PythonModel`                       |\n",
    "| Prompt/Chain Versioning       | Save all prompt templates and retriever logic as artifacts    |\n",
    "| Tool Tracking                 | Use callback-based logging to log each tool call/step         |\n",
    "| Advanced Feedback Integration | Integrate with tools like Trulens, WandB, or Weights & Biases |\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ **Key Tools and Techniques**\n",
    "\n",
    "| Function / Concept                    | Description                                                    |\n",
    "| ------------------------------------- | -------------------------------------------------------------- |\n",
    "| `mlflow.pyfunc.PythonModel`           | Base class to wrap agentic pipelines into deployable models    |\n",
    "| **Prompt Templates as Artifacts**     | Save `.txt` or `.json` prompts for audit/versioning            |\n",
    "| **Callback-Based Logging**            | Add hooks to log tool usage, retries, inputs/outputs           |\n",
    "| **External Loggers (Trulens, WandB)** | Add richer feedback tracking: bias, helpfulness, honesty, etc. |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### ðŸ” Integration with External GenAI Loggers\n",
    "\n",
    "| Tool                 | Purpose                             | MLflow Integration                        |\n",
    "| -------------------- | ----------------------------------- | ----------------------------------------- |\n",
    "| **Trulens**          | Log honesty, bias, coherence        | Export scores and log via `log_metrics()` |\n",
    "| **Weights & Biases** | Track experiments, graphs, feedback | Use WandB + MLflow side-by-side           |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Tips for Agent Tracking\n",
    "\n",
    "| Task                                  | Recommended Action                                           |\n",
    "| ------------------------------------- | ------------------------------------------------------------ |\n",
    "| Store dynamic prompt chains           | Log every `.txt` or `.json` prompt artifact used             |\n",
    "| Tool invocation analytics             | Add custom callback to log success/failure per tool          |\n",
    "| External evaluation (Trulens)         | Log with `mlflow.log_metrics()` during/after prediction loop |\n",
    "| Multi-agent orchestration (LangGraph) | Tag each step/tool output and save chain logs                |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### âœ… Real-Time Example: Wrap LangChain Agent with Logging + Prompt Artifacts\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 1. Define the PythonModel wrapper for your agent\n",
    "class MyAgentWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        tools = load_tools([\"serpapi\", \"llm-math\"], llm=ChatOpenAI(model=\"gpt-4o\"))\n",
    "        self.agent = initialize_agent(tools, ChatOpenAI(), agent=\"zero-shot-react-description\")\n",
    "\n",
    "    def predict(self, context, inputs):\n",
    "        query = inputs.iloc[0]  # assuming single-row input\n",
    "        return self.agent.run(query)\n",
    "\n",
    "# 2. Save prompt templates or logic as artifacts\n",
    "with open(\"prompt_template.txt\", \"w\") as f:\n",
    "    f.write(\"Use the toolset wisely and answer: {query}\")\n",
    "\n",
    "# 3. Log everything with MLflow\n",
    "with mlflow.start_run(run_name=\"agent-logging\"):\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent_model\",\n",
    "        python_model=MyAgentWrapper()\n",
    "    )\n",
    "    mlflow.log_artifact(\"prompt_template.txt\")\n",
    "    mlflow.log_params({\"agent_type\": \"react\", \"model\": \"gpt-4o\"})\n",
    "    mlflow.log_metrics({\"tools_used\": 2, \"tool_success_rate\": 0.98})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ“¦ How to Track Steps & Tools (Callback Pattern)\n",
    "\n",
    "#> For **LangChain**: Use `TracingCallbackHandler` or custom callbacks\n",
    "#> For **LangGraph**: Add logging inside `@tool` or `@node` decorated functions\n",
    "\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class MLflowLoggingCallback(BaseCallbackHandler):\n",
    "    def on_tool_end(self, output, **kwargs):\n",
    "        mlflow.log_metrics({\"last_tool_output_length\": len(output)})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-doc-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
